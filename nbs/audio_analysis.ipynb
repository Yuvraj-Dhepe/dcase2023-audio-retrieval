{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Splitting the captions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the original CSV file\n",
    "input_file = \"../curated_clotho_captions/clotho_captions_development.csv\"  # Replace with your actual file path\n",
    "output_folder = \"../agen_clotho_captions/random_seed_experiment/\"  # Replace with your desired output folder\n",
    "\n",
    "def split_csv(input_file, output_folder, num_chunks=10):\n",
    "    \"\"\"\n",
    "    Splits a CSV file into a specified number of chunks with uniform row distribution.\n",
    "\n",
    "    Parameters:\n",
    "        input_file (str): Path to the input CSV file.\n",
    "        output_folder (str): Directory where the output CSV files will be saved.\n",
    "        num_chunks (int): Number of chunks to split the CSV into (default is 10).\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Read the CSV into a DataFrame\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    # Calculate the size of each chunk\n",
    "    chunk_size = len(df) // num_chunks\n",
    "    remainder = len(df) % num_chunks\n",
    "\n",
    "    start = 0\n",
    "    for i in range(num_chunks):\n",
    "        # Calculate the end index for the current chunk\n",
    "        extra_row = 1 if i < remainder else 0  # Distribute remainder rows across the first few files\n",
    "        end = start + chunk_size + extra_row\n",
    "\n",
    "        # Slice the DataFrame for the current chunk\n",
    "        chunk_df = df.iloc[start:end]\n",
    "\n",
    "        # Save the chunk to a new CSV file\n",
    "        output_file = f\"{output_folder}chunk_{i+1}.csv\"\n",
    "        chunk_df.to_csv(output_file, index=False)\n",
    "\n",
    "        # Update the start index for the next chunk\n",
    "        start = end\n",
    "\n",
    "# Example usage\n",
    "split_csv(input_file, output_folder, num_chunks=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Expand the original captions csv file\n",
    "for i in range(1, 11):\n",
    "    expanded_df = expand_and_fill(\n",
    "        f\"../agen_clotho_captions/random_seed_experiment/chunk_{i}.csv\"\n",
    "    )\n",
    "    expanded_df.to_csv(\n",
    "        f\"../agen_clotho_captions/random_seed_experiment/expanded_captions_chunk_{i}.csv\",\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    input_csv_fp =f\"../agen_clotho_captions/random_seed_experiment/expanded_captions_chunk_{i}.csv\"\n",
    "    output_csv_fp = f\"../agen_clotho_captions/random_seed_experiment/agen_captions_chunk_{i}.csv\"\n",
    "    transform_csv(input_csv_fp, output_csv_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Expand original caption csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def expand_and_fill(csv_file):\n",
    "    \"\"\"\n",
    "    Expands the CSV by duplicating file names with caption suffixes\n",
    "    and fills caption columns accordingly.\n",
    "\n",
    "    Args:\n",
    "        csv_file (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with expanded entries and filled captions.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "    expanded_data = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        expanded_data.append(row.to_dict())  # Add original row\n",
    "\n",
    "        file_name = row[\"file_name\"]\n",
    "        for i in range(1, 6):\n",
    "            new_row = row.to_dict()  # Copy the entire row\n",
    "            new_row[\"file_name\"] = f\"{file_name[:-4]}_cap_{i}.wav\"\n",
    "\n",
    "            # Set all caption columns to \"N/A\" except the matching one\n",
    "            for j in range(1, 6):\n",
    "                new_row[f\"caption_{j}\"] = (\n",
    "                    \"N/A\" if i != j else row[f\"caption_{j}\"]\n",
    "                )\n",
    "\n",
    "            expanded_data.append(new_row)\n",
    "\n",
    "    return pd.DataFrame(expanded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "for split in [\"development\", \"validation\", \"evaluation\"]:\n",
    "    expanded_df = expand_and_fill(\n",
    "        f\"./curated_clotho_captions/clotho_captions_{split}.csv\"\n",
    "    )\n",
    "    expanded_df.to_csv(\n",
    "        f\"./agen_clotho_captions/clotho_expanded_captions_{split}.csv\",\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convert above generated csv's to row wise audio-raw_text-text pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "\n",
    "def parse_text(text):\n",
    "    \"\"\"Remove punctuation, convert to lowercase, and remove extra spaces.\"\"\"\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove extra spaces\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "\n",
    "def transform_csv(input_csv_fp, output_csv_fp):\n",
    "    \"\"\"From a normal file having a wav_fname with 5 caption columns, create 5 rows, 1 for each non-na caption column\"\"\"\n",
    "    # Load the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(input_csv_fp)\n",
    "\n",
    "    # Create a new DataFrame for the transformed data\n",
    "    transformed_df = pd.DataFrame(columns=[\"fname\", \"raw_text\", \"text\"])\n",
    "\n",
    "    # Iterate through each row in the original DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        file_name = row[\"file_name\"]\n",
    "        for i in range(1, 6):  # Loop through caption_1 to caption_num\n",
    "            caption = row[f\"caption_{i}\"]\n",
    "            if pd.notna(caption):  # Ensure the caption is not NaN\n",
    "                # Add the row to the transformed DataFrame\n",
    "                transformed_df = pd.concat(\n",
    "                    [\n",
    "                        transformed_df,\n",
    "                        pd.DataFrame(\n",
    "                            [\n",
    "                                {\n",
    "                                    \"fname\": file_name,\n",
    "                                    \"raw_text\": caption,\n",
    "                                    \"text\": parse_text(caption),\n",
    "                                }\n",
    "                            ]\n",
    "                        ),\n",
    "                    ],\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "\n",
    "    # Save the transformed DataFrame to the new CSV file\n",
    "    transformed_df.to_csv(output_csv_fp, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Provide the path to your input CSV file and the desired output CSV file\n",
    "for split in [\"development\", \"validation\", \"evaluation\"]:\n",
    "    input_csv_fp = (\n",
    "        f\"./agen_clotho_captions/clotho_expanded_captions_{split}.csv\"\n",
    "    )\n",
    "    output_csv_fp = f\"./agen_clotho_captions/agen_captions_{split}.csv\"\n",
    "    transform_csv(input_csv_fp, output_csv_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. From the above cell generated csv's, extract the information for every caption columns and create individual csv's\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def create_caption_csv_files(input_csv_fp, split, output_dir=\"./conf_yamls\"):\n",
    "    \"\"\"\n",
    "    Creates 5 CSV files, each containing captions for a specific caption index,\n",
    "    combined with the base captions.\n",
    "\n",
    "    Args:\n",
    "        input_csv_fp (str): Path to the input CSV file.\n",
    "        split (str): Identifier for the data split (e.g., 'evaluation', 'train').\n",
    "        output_dir (str, optional): Directory to save the output CSV files.\n",
    "            Defaults to './data'.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(input_csv_fp)\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        caption_index = i\n",
    "        output_subdir = os.path.join(\n",
    "            output_dir, f\"Clotho_caption_{caption_index}\"\n",
    "        )\n",
    "        os.makedirs(output_subdir, exist_ok=True)\n",
    "\n",
    "        # Filter rows for the current caption index\n",
    "        cap_row = df[df[\"fname\"].str.endswith(f\"_cap_{caption_index}.wav\")]\n",
    "\n",
    "        # Combine base rows and filtered rows\n",
    "        combined_df = pd.concat(\n",
    "            [df[~df[\"fname\"].str.contains(\"_cap_\")], cap_row],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "        # Save the combined DataFrame to a CSV file\n",
    "        output_csv_fp = os.path.join(output_subdir, f\"{split}_captions.csv\")\n",
    "        combined_df.to_csv(output_csv_fp, index=False)\n",
    "\n",
    "\n",
    "for split in [\"development\"]:\n",
    "    input_csv_file = f\"./agen_clotho_captions/agen_captions_{split}.csv\"\n",
    "    create_caption_csv_files(input_csv_file, split, output_dir=\"./data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. From the expanded csv, generate a single csv file filled with all captions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "# Function to normalize the text by converting to lowercase and removing extra punctuation\n",
    "\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Remove punctuation, convert to lowercase, and remove extra spaces.\"\"\"\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove extra spaces\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\n",
    "    \"agen_clotho_captions/clotho_expanded_captions_development.csv\"\n",
    ")\n",
    "\n",
    "# Reshape the dataframe by melting, gathering all caption columns into a single column\n",
    "df_melted = df.melt(\n",
    "    id_vars=[\"file_name\"],\n",
    "    value_vars=[\n",
    "        \"caption_1\",\n",
    "        \"caption_2\",\n",
    "        \"caption_3\",\n",
    "        \"caption_4\",\n",
    "        \"caption_5\",\n",
    "    ],\n",
    "    var_name=\"caption_column\",\n",
    "    value_name=\"raw_text\",\n",
    ")\n",
    "\n",
    "# Remove rows where the 'raw_text' is 'N/A' or empty\n",
    "df_filtered = df_melted.dropna(subset=[\"raw_text\"])\n",
    "df_filtered = df_filtered[df_filtered[\"raw_text\"] != \"N/A\"]\n",
    "\n",
    "# Add a new column with normalized text\n",
    "df_filtered[\"text\"] = df_filtered[\"raw_text\"].apply(normalize_text)\n",
    "\n",
    "# Sort the DataFrame to ensure that _cap_{num} files appear just after the original file\n",
    "df_filtered[\"sort_key\"] = df_filtered[\"file_name\"].str.replace(\n",
    "    r\"_cap_\\d+\", \"\", regex=True\n",
    ")  # Create a sort key\n",
    "df_filtered[\"is_cap\"] = df_filtered[\"file_name\"].str.contains(\n",
    "    r\"_cap_\\d+\"\n",
    ")  # Identify if it's a _cap file\n",
    "\n",
    "# Sort by the sort_key first, then by whether it's a _cap file or not\n",
    "df_sorted = df_filtered.sort_values(\n",
    "    by=[\"sort_key\", \"is_cap\", \"file_name\"]\n",
    ").drop(columns=[\"caption_column\", \"sort_key\", \"is_cap\"])\n",
    "\n",
    "# Select only the required columns\n",
    "df_final = df_sorted[[\"file_name\", \"raw_text\", \"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the transformed CSV to a new file\n",
    "df_final.to_csv(\n",
    "    \"agen_clotho_captions/transformed_development.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "def count_files_with_extensions(\n",
    "    folder_path: str, extensions: List[str]\n",
    ") -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Counts the number of files with each specified extension in a given folder.\n",
    "\n",
    "    :param folder_path: Path to the folder where files will be counted.\n",
    "    :param extensions: List of file extensions to look for (e.g., ['.txt', '.jpg']).\n",
    "    :return: Dictionary with extensions as keys and counts as values.\n",
    "    \"\"\"\n",
    "    counts = {\n",
    "        ext: 0 for ext in extensions\n",
    "    }  # Initialize a dictionary with each extension set to 0\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            for ext in extensions:\n",
    "                if file.endswith(ext):\n",
    "                    counts[ext] += 1\n",
    "\n",
    "    return counts\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "folder_path = \"data/Clotho_caption_2/development\"\n",
    "extensions = [\".wav\", \".csv\"]\n",
    "file_counts = count_files_with_extensions(folder_path, extensions)\n",
    "print(f\"File counts: {file_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load the CSV files into pandas DataFrames\n",
    "def count_fnames(captions_fp, clotho_captions_fp):\n",
    "    \"\"\"\n",
    "    Check whether the file_name in clotho_captions_{split}.csv are present 5 times in the {split}_captions.csv or not\n",
    "    \"\"\"\n",
    "    captions_file = pd.read_csv(captions_fp)  # First file\n",
    "    clotho_captions_file = pd.read_csv(clotho_captions_fp)  # Second file\n",
    "\n",
    "    # Count occurrences of each fname in the first file\n",
    "    fname_counts = captions_file[\"fname\"].value_counts()\n",
    "\n",
    "    # Extract the file_name column from the second file\n",
    "    file_names = clotho_captions_file[\"file_name\"]\n",
    "\n",
    "    # Check if each file_name from the second file occurs exactly 5 times in the first file\n",
    "    for file_name in file_names:\n",
    "        count = fname_counts.get(file_name, 0)\n",
    "        if count != 5:\n",
    "            print(\n",
    "                f\"{file_name} does NOT occur exactly 5 times in the first file. It occurs {count} times.\"\n",
    "            )\n",
    "\n",
    "\n",
    "count_fnames(\n",
    "    captions_fp=\"./data/Clotho/development_captions.csv\",\n",
    "    clotho_captions_fp=\"./data/clotho_captions_development.csv\",\n",
    ")\n",
    "count_fnames(\n",
    "    captions_fp=\"./data/Clotho/validation_captions.csv\",\n",
    "    clotho_captions_fp=\"./data/clotho_captions_validation.csv\",\n",
    ")\n",
    "count_fnames(\n",
    "    captions_fp=\"./data/Clotho/evaluation_captions.csv\",\n",
    "    clotho_captions_fp=\"./data/clotho_captions_evaluation.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def check_captions(file_name, df1, df2):\n",
    "    # Filter df1 rows for the given file_name\n",
    "    df1_filtered = df1[df1[\"fname\"] == file_name]\n",
    "\n",
    "    # Get all captions for the file_name from df2\n",
    "    captions_in_df2 = df2[df2[\"file_name\"] == file_name].iloc[0, 1:].tolist()\n",
    "    # Check if each caption in df2 exists in the 'raw_text' column of the filtered df1\n",
    "    captions_in_df1 = df1_filtered[\"raw_text\"].tolist()\n",
    "    missing_captions = [\n",
    "        caption\n",
    "        for caption in captions_in_df2\n",
    "        if caption not in captions_in_df1\n",
    "    ]\n",
    "\n",
    "    if not missing_captions:\n",
    "        print(end=\"\")\n",
    "    else:\n",
    "        print(f\"Missing captions for '{file_name}': {missing_captions}\")\n",
    "\n",
    "\n",
    "def main_check_function(captions_fp, clotho_captions_fp):\n",
    "    \"\"\"\n",
    "    Check whether all the 5 captions from clotho_captions_{split}.csv file are present iteratively in rows in {split}_captions.csv\n",
    "    \"\"\"\n",
    "    df1 = pd.read_csv(captions_fp)\n",
    "    df2 = pd.read_csv(clotho_captions_fp)\n",
    "\n",
    "    # Check for each file_name in df2\n",
    "    file_names = df2[\"file_name\"]\n",
    "    for file_name in file_names:\n",
    "        check_captions(file_name, df1, df2)\n",
    "\n",
    "\n",
    "main_check_function(\n",
    "    captions_fp=\"./data/Clotho/development_captions.csv\",\n",
    "    clotho_captions_fp=\"./curated_clotho_captions/clotho_captions_development.csv\",\n",
    ")\n",
    "main_check_function(\n",
    "    captions_fp=\"./data/Clotho/validation_captions.csv\",\n",
    "    clotho_captions_fp=\"./curated_clotho_captions/clotho_captions_validation.csv\",\n",
    ")\n",
    "main_check_function(\n",
    "    captions_fp=\"./data/Clotho/evaluation_captions.csv\",\n",
    "    clotho_captions_fp=\"./curated_clotho_captions/clotho_captions_evaluation.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def compare_dataframes(df1, df2):\n",
    "    # Ensure both DataFrames have the same shape\n",
    "    if df1.shape != df2.shape:\n",
    "        raise ValueError(\"DataFrames must have the same shape to compare.\")\n",
    "\n",
    "    # Initialize an empty DataFrame to store the differences\n",
    "    diff_df = pd.DataFrame(columns=[\"col_1\", \"col_2\"])\n",
    "\n",
    "    # Iterate through each row in the DataFrames\n",
    "    for idx in range(df1.shape[0]):\n",
    "        row1 = df1.iloc[idx]\n",
    "        row2 = df2.iloc[idx]\n",
    "\n",
    "        # Check if there are any differences between the rows\n",
    "        if not row1.equals(row2):\n",
    "            # Append rows from both DataFrames to the diff_df\n",
    "            diff_df = pd.concat(\n",
    "                [\n",
    "                    diff_df,\n",
    "                    pd.DataFrame(\n",
    "                        {\"col_1\": [row1.to_dict()], \"col_2\": [row2.to_dict()]}\n",
    "                    ),\n",
    "                ],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "\n",
    "    return diff_df\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(\"data/Clotho_caption_1/transformed_captions.csv\")\n",
    "df2 = pd.read_csv(\"data/Clotho/development_captions.csv\")\n",
    "\n",
    "# Compare the DataFrames\n",
    "diff_df = compare_dataframes(df1, df2)\n",
    "\n",
    "# Save the differences to a CSV file if needed\n",
    "diff_df.to_csv(\"./data/differences.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
