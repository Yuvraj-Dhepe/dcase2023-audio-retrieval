{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Influence of Random Seeds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro, ttest_ind\n",
    "\n",
    "def analyze_seed_impact(df, metric_column, seed_1, seed_2, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Analyze the impact of random seeds on a specific metric using normality testing and a t-test.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing the data.\n",
    "        metric_column (str): The name of the column with the metric values to compare.\n",
    "        seed_1 (int): The first random seed to compare.\n",
    "        seed_2 (int): The second random seed to compare.\n",
    "        alpha (float): Significance level for hypothesis testing (default is 0.05).\n",
    "\n",
    "    Returns:\n",
    "        None: Prints the analysis results.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 90)\n",
    "    print(f\"Analyzing impact of random seeds {seed_1} and {seed_2} on metric: {metric_column}\")\n",
    "    print(\"=\" * 90)\n",
    "\n",
    "    # Extract metric values for the specified seeds\n",
    "    seed_1_metrics = df[df['seed'] == seed_1][metric_column].values\n",
    "    seed_2_metrics = df[df['seed'] == seed_2][metric_column].values\n",
    "\n",
    "    print(f\"Number of samples for Seed {seed_1}: {len(seed_1_metrics)}\")\n",
    "    print(f\"Number of samples for Seed {seed_2}: {len(seed_2_metrics)}\")\n",
    "\n",
    "    # Normality testing with Shapiro-Wilk test\n",
    "    print(\"\\nStep 1: Checking Normality (Shapiro-Wilk Test)\")\n",
    "    shapiro_seed_1 = shapiro(seed_1_metrics)\n",
    "    shapiro_seed_2 = shapiro(seed_2_metrics)\n",
    "\n",
    "    print(f\"Shapiro-Wilk test for Seed {seed_1}: W={shapiro_seed_1.statistic:.4f}, p={shapiro_seed_1.pvalue:.4f}\")\n",
    "    print(f\"Shapiro-Wilk test for Seed {seed_2}: W={shapiro_seed_2.statistic:.4f}, p={shapiro_seed_2.pvalue:.4f}\")\n",
    "\n",
    "    if shapiro_seed_1.pvalue < alpha or shapiro_seed_2.pvalue < alpha:\n",
    "        print(\"At least one group is not normally distributed. Consider using a non-parametric test.\")\n",
    "        return\n",
    "\n",
    "    print(\"Both groups appear to be normally distributed. Proceeding with the t-test.\")\n",
    "\n",
    "    # Perform a two-sided t-test\n",
    "    print(\"\\nStep 2: Performing Two-Sample T-Test\")\n",
    "    t_stat, p_value = ttest_ind(seed_1_metrics, seed_2_metrics)\n",
    "\n",
    "    print(f\"T-statistic: {t_stat:.4f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "    # Interpret the t-test result\n",
    "    print(\"\\nStep 3: Interpreting Results\")\n",
    "    if p_value < alpha:\n",
    "        print(\"Reject the null hypothesis: The random seeds significantly influence performance.\")\n",
    "    else:\n",
    "        print(\"Fail to reject the null hypothesis: No significant difference due to random seeds.\")\n",
    "\n",
    "    print(\"=\" * 90)\n",
    "\n",
    "df = pd.read_csv('../random_seed_based_experiment/a.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_seed_impact(df, metric_column='eval_Txt2Audio_mAP', seed_1=42, seed_2=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_seed_impact(df, metric_column='eval_Audio2Txt_mAP', seed_1=42, seed_2=88)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlating Objective Loss Values and Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"HPT_Nov_09_Evaluated\"\n",
    "folder_name = \"z_results\"\n",
    "columns_to_correlate = [\n",
    "    # \"after_train_eval_obj\", # The collumn to correlate with alternatively with val_obj\n",
    "    \"val_obj\",\n",
    "    \"eval_Txt2Audio_mAP\",\n",
    "    \"eval_Txt2Audio_R10\",\n",
    "    \"eval_Txt2Audio_R5\",\n",
    "    # \"eval_Txt2Audio_R1\",\n",
    "    \"eval_Audio2Txt_mAP\",\n",
    "    \"eval_Audio2Txt_R10\",\n",
    "    \"eval_Audio2Txt_R5\",\n",
    "    # \"eval_Audio2Txt_R1\",\n",
    "    \"val_Txt2Audio_mAP\",\n",
    "    \"val_Txt2Audio_R10\",\n",
    "    \"val_Txt2Audio_R5\",\n",
    "    # \"val_Txt2Audio_R1\",\n",
    "    \"val_Audio2Txt_mAP\",\n",
    "    \"val_Audio2Txt_R10\",\n",
    "    \"val_Audio2Txt_R5\",\n",
    "    # \"val_Audio2Txt_R1\",\n",
    "]\n",
    "to_correlate_with = \"after_train_eval_obj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "\n",
    "set_matplotlib_formats(\"svg\")\n",
    "# Load CSV data\n",
    "\n",
    "csv_path = f\"../{folder_name}/{file_name}.csv\"  # adjust path if needed\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Columns to correlate with \"val_obj\"\n",
    "\n",
    "\n",
    "# Calculate Pearson and Spearman correlations with \"val_obj\" and their p-values\n",
    "pearson_corrs = {}\n",
    "spearman_corrs = {}\n",
    "\n",
    "for col in columns_to_correlate:\n",
    "    pearson_corr, pearson_pval = stats.pearsonr(\n",
    "        df[f\"{to_correlate_with}\"], df[col]\n",
    "    )\n",
    "    spearman_corr, spearman_pval = stats.spearmanr(\n",
    "        df[f\"{to_correlate_with}\"], df[col]\n",
    "    )\n",
    "\n",
    "    pearson_corrs[col] = (pearson_corr, pearson_pval)\n",
    "    spearman_corrs[col] = (spearman_corr, spearman_pval)\n",
    "\n",
    "# Create dataframes for correlations and p-values (log transformed)\n",
    "pearson_df = pd.DataFrame(\n",
    "    [\n",
    "        (\n",
    "            col,\n",
    "            pearson_corrs[col][0],\n",
    "            (\n",
    "                np.log10(pearson_corrs[col][1])\n",
    "                if pearson_corrs[col][1] > 0\n",
    "                else 0\n",
    "            ),\n",
    "        )\n",
    "        for col in columns_to_correlate\n",
    "    ],\n",
    "    columns=[\"Metric\", \"Pearson_Correlation\", \"Log10_Pearson_P-value\"],\n",
    ")\n",
    "\n",
    "spearman_df = pd.DataFrame(\n",
    "    [\n",
    "        (\n",
    "            col,\n",
    "            spearman_corrs[col][0],\n",
    "            (\n",
    "                np.log10(spearman_corrs[col][1])\n",
    "                if spearman_corrs[col][1] > 0\n",
    "                else 0\n",
    "            ),\n",
    "        )\n",
    "        for col in columns_to_correlate\n",
    "    ],\n",
    "    columns=[\"Metric\", \"Spearman_Correlation\", \"Log10_Spearman_P-value\"],\n",
    ")\n",
    "\n",
    "# Log the Pearson and Spearman p-values after transformation\n",
    "# print(\"Logged Pearson and Spearman Correlations and Log10 P-values:\\n\")\n",
    "# print(\"Pearson Correlations and Log10 P-values:\")\n",
    "# print(pearson_df)\n",
    "# print(\"\\nSpearman Correlations and Log10 P-values:\")\n",
    "# print(spearman_df)\n",
    "\n",
    "# Plot correlations and log-transformed p-values with 'lava' colormap\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12), dpi=150)\n",
    "\n",
    "# Pearson Correlation Plot with lava colormap\n",
    "sns.barplot(\n",
    "    data=pearson_df.sort_values(by=\"Pearson_Correlation\", ascending=False),\n",
    "    x=\"Pearson_Correlation\",\n",
    "    y=\"Metric\",\n",
    "    ax=axes[0, 0],\n",
    "    palette=\"viridis\",  # 'viridis' is similar to 'lava' and provides a vibrant color scale\n",
    ")\n",
    "axes[0, 0].set_title(f\"Pearson Correlation with {to_correlate_with}\")\n",
    "\n",
    "\n",
    "# Spearman Correlation Plot with lava colormap\n",
    "sns.barplot(\n",
    "    data=spearman_df.sort_values(by=\"Spearman_Correlation\", ascending=False),\n",
    "    x=\"Spearman_Correlation\",\n",
    "    y=\"Metric\",\n",
    "    ax=axes[0, 1],\n",
    "    palette=\"viridis\",\n",
    "    legend=True,\n",
    ")\n",
    "axes[0, 1].set_title(f\"Spearman Correlation with {to_correlate_with}\")\n",
    "\n",
    "# Log10 Pearson P-value Plot with lava colormap\n",
    "sns.barplot(\n",
    "    data=pearson_df.sort_values(by=\"Log10_Pearson_P-value\", ascending=False),\n",
    "    x=\"Log10_Pearson_P-value\",\n",
    "    y=\"Metric\",\n",
    "    ax=axes[1, 0],\n",
    "    palette=\"rainbow\",\n",
    "    legend=True,\n",
    ")\n",
    "axes[1, 0].set_title(\"Log10 Pearson P-values\")\n",
    "\n",
    "# Log10 Spearman P-value Plot with lava colormap\n",
    "sns.barplot(\n",
    "    data=spearman_df.sort_values(by=\"Log10_Spearman_P-value\", ascending=False),\n",
    "    x=\"Log10_Spearman_P-value\",\n",
    "    y=\"Metric\",\n",
    "    ax=axes[1, 1],\n",
    "    palette=\"rainbow\",\n",
    "    legend=True,\n",
    ")\n",
    "axes[1, 1].set_title(\"Log10 Spearman P-values\")\n",
    "\n",
    "output_path = f\"../{folder_name}/{to_correlate_with}_{file_name}.svg\"\n",
    "# Adjust layout for better presentation\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_path, bbox_inches=\"tight\", format=\"svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up the figure\n",
    "plt.figure(figsize=(15, 20), dpi=150)\n",
    "\n",
    "# Iterate over each column and create a scatter plot or other plot\n",
    "for i, col in enumerate(columns_to_correlate, 1):\n",
    "    plt.subplot(4, 4, i)  # Create a grid of subplots (5 rows, 3 columns)\n",
    "\n",
    "    # Plot scatter plot\n",
    "    sns.scatterplot(x=df[f\"{to_correlate_with}\"], y=df[col])\n",
    "\n",
    "    # Set the title and labels\n",
    "    plt.title(f\"{to_correlate_with} vs {col}\")\n",
    "    plt.xlabel(f\"{to_correlate_with}\")\n",
    "    plt.ylabel(col)\n",
    "\n",
    "output_path = f\"../{folder_name}/{to_correlate_with}_{file_name}_scatter.svg\"\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_path, bbox_inches=\"tight\", format=\"svg\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
