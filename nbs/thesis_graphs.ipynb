{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import nltk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "import librosa.display\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.patches import Circle\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.patches import FancyArrow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Graphs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio as WaveForm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Waveform is a visual representation of the audio signal, where the x-axis represents time and the y-axis represents amplitude.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fig_to_pdf(fig, save_name):\n",
    "    \"\"\"\n",
    "    Saves the given plt figure object to a PDF.\n",
    "\n",
    "    :param fig: matplotlib.pyplot figure object to be saved.\n",
    "    :param save_name: The name of the file to save the figure as.\n",
    "    \"\"\"\n",
    "    # Save the figure as a PDF with the given file name\n",
    "    fig.savefig(save_name, dpi=150)\n",
    "    print(f\"Waveform saved as PDF at: {save_name}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_waveform(input_file):\n",
    "    \"\"\"\n",
    "    Plots the waveform for the given audio file.\n",
    "\n",
    "    :param input_file: Path to the input audio file.\n",
    "    :return: plt.figure object.\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    array, sampling_rate = librosa.load(input_file)\n",
    "\n",
    "    # Create the plot\n",
    "    fig = plt.figure(\n",
    "        figsize=(12, 4), dpi=150\n",
    "    )  # Set the figure size (width x height in inches)\n",
    "    librosa.display.waveshow(\n",
    "        array, sr=sampling_rate, color=\"#800080\"\n",
    "    )  # Plot the waveform\n",
    "\n",
    "    # Beautify the plot\n",
    "    plt.title(\"Audio Waveform\", fontsize=16)\n",
    "    plt.xlabel(\"Time (seconds)\", fontsize=14)\n",
    "    plt.ylabel(\"Amplitude\", fontsize=14)\n",
    "    plt.grid(True, linestyle=\"-\", alpha=0.5)  # Add a grid\n",
    "    plt.tight_layout()  # Adjust layout to avoid clipping\n",
    "\n",
    "    return array, sampling_rate, fig\n",
    "\n",
    "\n",
    "# Example usage\n",
    "input_file = \"../example/chant.mp3\"\n",
    "array, sr, fig = plot_waveform(input_file)  # Generate the plot\n",
    "save_fig_to_pdf(fig, \"../example/01_waveform.pdf\")  # Save the plot as a PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio as Frequency Spectrum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Frequency Spectrumrum plots the strength of the various frequency components that are present in this audio segment. The frequency values are on the x-axis, usually plotted on a logarithmic scale, while their amplitudes are on the y-axis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dft(input_file, num_samples=500000):\n",
    "    \"\"\"\n",
    "    Plots the DFT (Discrete Fourier Transform) of the given audio file.\n",
    "\n",
    "    :param input_file: Path to the input audio file.\n",
    "    :param num_samples: Number of samples to use from the beginning of the audio file for DFT.\n",
    "    :return: plt.figure object.\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    array, sr = librosa.load(input_file)\n",
    "\n",
    "    # Taking only the first num_samples for better visualization\n",
    "    dft_input = array[:num_samples]\n",
    "\n",
    "    # Compute the DFT of the input signal\n",
    "    window = np.hanning(len(dft_input))\n",
    "    windowed_input = dft_input * window\n",
    "    dft = np.fft.rfft(windowed_input)\n",
    "\n",
    "    # Get the amplitude spectrum in decibels\n",
    "    amplitude = np.abs(dft)\n",
    "    amplitude_db = librosa.amplitude_to_db(amplitude, ref=np.max)\n",
    "\n",
    "    # Get the frequency bins\n",
    "    frequency = librosa.fft_frequencies(sr=sr, n_fft=len(dft_input))\n",
    "\n",
    "    # Create the plot\n",
    "    fig = plt.figure(\n",
    "        figsize=(12, 4), dpi=150\n",
    "    )  # Set the figure size (width x height in inches)\n",
    "    plt.plot(frequency, amplitude_db)\n",
    "    plt.xlabel(\"Frequency (Hz)\")\n",
    "    plt.ylabel(\"Amplitude (dB)\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.title(\"DFT of Audio Signal\", fontsize=16)\n",
    "    plt.tight_layout()  # Adjust layout to avoid clipping\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig = plot_dft(input_file)\n",
    "save_fig_to_pdf(fig, \"../example/02_dft.pdf\")  # Save the plot as a PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio as Spectrogram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Spectrum only shows a frozen snapshot of the frequencies at a given instant.\n",
    "- The solution is to take multiple DFTs, each covering only a small slice of time, and stack the resulting spectra together into a spectrogram.\n",
    "- A spectrogram plots the frequency content of an audio signal as it changes over time. It allows you to see time, frequency, and amplitude all on one graph. The algorithm that performs this computation is the STFT or Short Time Fourier Transform.\n",
    "- The spectrogram is one of the most informative audio tools available to you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stft(input_file):\n",
    "    \"\"\"\n",
    "    Plots the Short-Time Fourier Transform (STFT) of the given audio file.\n",
    "\n",
    "    :param input_file: Path to the input audio file.\n",
    "    :return: plt.figure object.\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    array, sr = librosa.load(input_file)\n",
    "\n",
    "    # Compute the Short-Time Fourier Transform (STFT)\n",
    "    D = librosa.stft(array)\n",
    "\n",
    "    # Convert the amplitude to decibels\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "\n",
    "    # Create the plot\n",
    "    fig = plt.figure(\n",
    "        figsize=(12, 4), dpi=150\n",
    "    )  # Set the figure size (width x height in inches)\n",
    "    librosa.display.specshow(S_db, x_axis=\"time\", y_axis=\"hz\")\n",
    "    plt.colorbar(format=\"%+2.0f dB\")\n",
    "    plt.title(\"STFT Magnitude (in dB)\", fontsize=16)\n",
    "    plt.tight_layout()  # Adjust layout to avoid clipping\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Example usage\n",
    "input_file = librosa.ex(\"trumpet\")  # Example trumpet sound from librosa\n",
    "fig = plot_stft(input_file)  # Generate the STFT plot\n",
    "save_fig_to_pdf(fig, \"../example/03_stft.pdf\")  # Save the plot as a PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mel Spectograms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A mel spectrogram is a variation of the spectrogram that is commonly used in speech processing and machine learning tasks. It is similar to a spectrogram in that it shows the frequency content of an audio signal over time, but on a different frequency axis.\n",
    "- In a standard spectrogram, the frequency axis is linear and is measured in hertz (Hz). However, the human auditory system is more sensitive to changes in lower frequencies than higher frequencies, and this sensitivity decreases logarithmically as frequency increases. The mel scale is a perceptual scale that approximates the non-linear frequency response of the human ear.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_melspectrogram(input_file, n_mels=128, fmax=8000):\n",
    "    \"\"\"\n",
    "    Plots the Mel spectrogram of the given audio file.\n",
    "\n",
    "    :param input_file: Path to the input audio file.\n",
    "    :param n_mels: Number of Mel bands (default: 128).\n",
    "    :param fmax: Maximum frequency for Mel scale (default: 8000 Hz).\n",
    "    :return: plt.figure object.\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    array, sr = librosa.load(input_file)\n",
    "\n",
    "    # Compute the Mel spectrogram\n",
    "    S = librosa.feature.melspectrogram(\n",
    "        y=array, sr=sr, n_mels=n_mels, fmax=fmax\n",
    "    )\n",
    "\n",
    "    # Convert the Mel spectrogram to decibels\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "    # Create the plot\n",
    "    fig = plt.figure(\n",
    "        figsize=(12, 4), dpi=150\n",
    "    )  # Set the figure size (width x height in inches)\n",
    "    librosa.display.specshow(\n",
    "        S_dB, x_axis=\"time\", y_axis=\"mel\", sr=sr, fmax=fmax\n",
    "    )\n",
    "    plt.colorbar(format=\"%+2.0f dB\")\n",
    "    plt.title(\n",
    "        f\"Mel Spectrogram (n_mels={n_mels}, fmax={fmax} Hz)\", fontsize=16\n",
    "    )\n",
    "    plt.tight_layout()  # Adjust layout to avoid clipping\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Example usage\n",
    "input_file = librosa.ex(\"trumpet\")  # Example trumpet sound from librosa\n",
    "fig = plot_melspectrogram(input_file)  # Generate the Mel spectrogram plot\n",
    "save_fig_to_pdf(fig, \"../example/04_melspectrogram.pdf\")  # S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mel_filter_bank(\n",
    "    num_filters=10, num_fft_bins=128, mel_min=0, mel_max=1100\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a Mel filter bank and returns the figure object.\n",
    "\n",
    "    Parameters:\n",
    "        num_filters (int): Number of Mel filters.\n",
    "        num_fft_bins (int): Number of FFT bins.\n",
    "        mel_min (float): Minimum value in the Mel scale.\n",
    "        mel_max (float): Maximum value in the Mel scale.\n",
    "\n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: Figure object with the Mel filter bank plot.\n",
    "    \"\"\"\n",
    "    # Generate linearly spaced points in the Mel scale\n",
    "    mel_points = np.linspace(mel_min, mel_max, num_filters + 2)\n",
    "    bin_points = np.floor(mel_points / mel_max * (num_fft_bins - 1)).astype(\n",
    "        int\n",
    "    )\n",
    "\n",
    "    # Initialize filter bank\n",
    "    filter_bank = np.zeros((num_filters, num_fft_bins))\n",
    "\n",
    "    # Create triangular Mel filters\n",
    "    for i in range(1, len(bin_points) - 1):\n",
    "        start, center, end = (\n",
    "            bin_points[i - 1],\n",
    "            bin_points[i],\n",
    "            bin_points[i + 1],\n",
    "        )\n",
    "\n",
    "        # Left slope\n",
    "        filter_bank[i - 1, start : center + 1] = np.linspace(\n",
    "            0, 1, center - start + 1\n",
    "        )\n",
    "        # Right slope\n",
    "        filter_bank[i - 1, center : end + 1] = np.linspace(\n",
    "            1, 0, end - center + 1\n",
    "        )\n",
    "\n",
    "    # Plot the Mel filter bank\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), dpi=150)\n",
    "    for i in range(num_filters):\n",
    "        ax.plot(filter_bank[i], label=f\"Filter {i + 1}\")\n",
    "    ax.set_title(\"Mel Filter Bank\")\n",
    "    ax.set_xlabel(\"FFT Bin Index\")\n",
    "    ax.set_ylabel(\"Amplitude\")\n",
    "    ax.grid(True)\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Generate the Mel filter bank figure\n",
    "mel_filter_fig = create_mel_filter_bank()\n",
    "save_fig_to_pdf(mel_filter_fig, \"../example/05_mel_filter_bank.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN OverFitting and UnderFitting Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fitting_examples(output_filename):\n",
    "    \"\"\"\n",
    "    Creates plots demonstrating underfitting, good fit, and overfitting, including the true function,\n",
    "    and saves the result to a PDF file.\n",
    "\n",
    "    Parameters:\n",
    "        output_filename (str): The name of the output PDF file (e.g., 'fitting_examples.pdf').\n",
    "    \"\"\"\n",
    "    # Generate sample data\n",
    "    np.random.seed(42)\n",
    "    x = np.linspace(0, 10, 100)\n",
    "    y_true = np.sin(x)  # True function\n",
    "    y = y_true + 0.2 * np.random.normal(size=x.shape)  # Noisy observations\n",
    "\n",
    "    # Underfitting model (Linear)\n",
    "    coeff_underfit = np.polyfit(x, y, 1)\n",
    "    y_underfit = np.polyval(coeff_underfit, x)\n",
    "\n",
    "    # Good fit model (Polynomial degree 5)\n",
    "    coeff_goodfit = np.polyfit(x, y, 5)\n",
    "    y_goodfit = np.polyval(coeff_goodfit, x)\n",
    "\n",
    "    # Overfitting model (Polynomial degree 15)\n",
    "    coeff_overfit = np.polyfit(x, y, 15)\n",
    "    y_overfit = np.polyval(coeff_overfit, x)\n",
    "\n",
    "    # Plotting\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharey=True, dpi=150)\n",
    "\n",
    "    # Underfitting plot\n",
    "    axes[0].scatter(x, y, label=\"Data\", color=\"blue\", s=10)\n",
    "    axes[0].plot(x, y_underfit, label=\"Underfitting (Linear)\", color=\"red\")\n",
    "    axes[0].plot(\n",
    "        x,\n",
    "        y_true,\n",
    "        label=\"True Function (sin(x))\",\n",
    "        color=\"black\",\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "    axes[0].set_title(\"Underfitting\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Good fit plot\n",
    "    axes[1].scatter(x, y, label=\"Data\", color=\"blue\", s=10)\n",
    "    axes[1].plot(x, y_goodfit, label=\"Good Fit (Degree 5)\", color=\"green\")\n",
    "    axes[1].plot(\n",
    "        x,\n",
    "        y_true,\n",
    "        label=\"True Function (sin(x))\",\n",
    "        color=\"black\",\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "    axes[1].set_title(\"Good Fit\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    # Overfitting plot\n",
    "    axes[2].scatter(x, y, label=\"Data\", color=\"blue\", s=10)\n",
    "    axes[2].plot(x, y_overfit, label=\"Overfitting (Degree 15)\", color=\"orange\")\n",
    "    axes[2].plot(\n",
    "        x,\n",
    "        y_true,\n",
    "        label=\"True Function (sin(x))\",\n",
    "        color=\"black\",\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "    axes[2].set_title(\"Overfitting\")\n",
    "    axes[2].legend()\n",
    "\n",
    "    # Add common labels\n",
    "    fig.supylabel(\"Output\")\n",
    "    fig.supxlabel(\"Input\")\n",
    "\n",
    "    # Save the figure to a PDF\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(output_filename, format=\"pdf\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "plot_fitting_examples(\"../example/06_fitting_concept.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoEncoder Diagram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_autoencoder_diagram(output_pdf=\"autoencoder_diagram.pdf\"):\n",
    "    \"\"\"\n",
    "    Generates a high-quality PDF diagram of an Autoencoder architecture.\n",
    "\n",
    "    Parameters:\n",
    "    - output_pdf (str): The filename for the output PDF file.\n",
    "    \"\"\"\n",
    "    # Create a new figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), dpi=150)\n",
    "\n",
    "    # Define layer positions\n",
    "    input_layer = [-2, 0, 2]\n",
    "    hidden_layer = [-1, 0, 1]\n",
    "    bottleneck_layer = [0]\n",
    "    decoder_layer = [-1, 0, 1]\n",
    "    output_layer = [-2, 0, 2]\n",
    "\n",
    "    # Helper to draw nodes\n",
    "    def draw_nodes(layer, x, label=None, color=\"lightblue\"):\n",
    "        for y in layer:\n",
    "            ax.add_patch(Circle((x, y), 0.3, color=color, ec=\"black\", lw=1.5))\n",
    "        if label:\n",
    "            ax.text(\n",
    "                x,\n",
    "                max(layer) + 0.8,\n",
    "                label,\n",
    "                ha=\"center\",\n",
    "                fontsize=12,\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "\n",
    "    # Draw nodes for each layer\n",
    "    draw_nodes(input_layer, -3, label=\"Input Layer\", color=\"lightcoral\")\n",
    "    draw_nodes(hidden_layer, -1.5, label=\"Encoder\", color=\"lightblue\")\n",
    "    draw_nodes(bottleneck_layer, 0, label=\"Latent Space\", color=\"gold\")\n",
    "    draw_nodes(decoder_layer, 1.5, label=\"Decoder\", color=\"lightgreen\")\n",
    "    draw_nodes(output_layer, 3, label=\"Output Layer\", color=\"lightcoral\")\n",
    "\n",
    "    # Helper to draw connections\n",
    "    def draw_connections(layer1, x1, layer2, x2, color=\"gray\", alpha=0.7):\n",
    "        for y1 in layer1:\n",
    "            for y2 in layer2:\n",
    "                ax.add_patch(\n",
    "                    FancyArrow(\n",
    "                        x1 + 0.3,\n",
    "                        y1,\n",
    "                        x2 - x1 - 0.6,\n",
    "                        y2 - y1,\n",
    "                        width=0.01,\n",
    "                        color=color,\n",
    "                        alpha=alpha,\n",
    "                        head_width=0.1,\n",
    "                        length_includes_head=True,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    # Draw connections between layers\n",
    "    draw_connections(input_layer, -3, hidden_layer, -1.5)\n",
    "    draw_connections(\n",
    "        hidden_layer, -1.5, bottleneck_layer, 0, color=\"green\", alpha=0.8\n",
    "    )\n",
    "    draw_connections(\n",
    "        bottleneck_layer, 0, decoder_layer, 1.5, color=\"blue\", alpha=0.8\n",
    "    )\n",
    "    draw_connections(decoder_layer, 1.5, output_layer, 3)\n",
    "\n",
    "    # Add labels for data flow\n",
    "    ax.text(-3, -3, \"Input Data\", ha=\"center\", fontsize=10)\n",
    "    ax.text(3, -3, \"Reconstructed Output\", ha=\"center\", fontsize=10)\n",
    "\n",
    "    # Aesthetic adjustments\n",
    "    ax.set_xlim(-4, 4)\n",
    "    ax.set_ylim(-4, 4)\n",
    "    ax.axis(\"off\")\n",
    "    # plt.title(\"Autoencoder Architecture\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "    # Save the figure as a high-quality PDF\n",
    "    fig.savefig(output_pdf, format=\"pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "    print(f\"Diagram saved as {output_pdf}\")\n",
    "\n",
    "    # Close the plot\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# Call the function\n",
    "generate_autoencoder_diagram(\"../example/14_autoencoder_architecture.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autoencoder Diagram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vae_diagram(output_pdf=\"vae_diagram.pdf\"):\n",
    "    \"\"\"\n",
    "    Generates a high-quality PDF diagram of a Variational Autoencoder (VAE) architecture.\n",
    "\n",
    "    Parameters:\n",
    "    - output_pdf (str): The filename for the output PDF file.\n",
    "    \"\"\"\n",
    "    # Create a new figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 7), dpi=150)\n",
    "\n",
    "    # Define layer positions\n",
    "    input_layer = [-2, 0, 2]\n",
    "    hidden_layer = [-1, 0, 1]\n",
    "    latent_space = [0]\n",
    "    decoder_layer = [-1, 0, 1]\n",
    "    output_layer = [-2, 0, 2]\n",
    "\n",
    "    # Helper to draw nodes\n",
    "    def draw_nodes(layer, x, label=None, color=\"lightblue\"):\n",
    "        for y in layer:\n",
    "            ax.add_patch(Circle((x, y), 0.3, color=color, ec=\"black\", lw=1.5))\n",
    "        if label:\n",
    "            ax.text(\n",
    "                x,\n",
    "                max(layer) + 0.8,\n",
    "                label,\n",
    "                ha=\"center\",\n",
    "                fontsize=12,\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "\n",
    "    # Draw nodes for each layer\n",
    "    draw_nodes(input_layer, -4, label=\"Input Layer\", color=\"lightcoral\")\n",
    "    draw_nodes(hidden_layer, -2, label=\"Encoder\", color=\"lightblue\")\n",
    "    draw_nodes(latent_space, 0, label=\"Latent Space\", color=\"gold\")\n",
    "    draw_nodes(decoder_layer, 2, label=\"Decoder\", color=\"lightgreen\")\n",
    "    draw_nodes(output_layer, 4, label=\"Output Layer\", color=\"lightcoral\")\n",
    "\n",
    "    # Draw connections between layers\n",
    "    def draw_connections(layer1, x1, layer2, x2, color=\"gray\", alpha=0.7):\n",
    "        for y1 in layer1:\n",
    "            for y2 in layer2:\n",
    "                ax.add_patch(\n",
    "                    FancyArrow(\n",
    "                        x1 + 0.3,\n",
    "                        y1,\n",
    "                        x2 - x1 - 0.6,\n",
    "                        y2 - y1,\n",
    "                        width=0.01,\n",
    "                        color=color,\n",
    "                        alpha=alpha,\n",
    "                        head_width=0.1,\n",
    "                        length_includes_head=True,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    draw_connections(input_layer, -4, hidden_layer, -2)\n",
    "    draw_connections(\n",
    "        hidden_layer, -2, latent_space, 0, color=\"green\", alpha=0.8\n",
    "    )\n",
    "    draw_connections(\n",
    "        latent_space, 0, decoder_layer, 2, color=\"blue\", alpha=0.8\n",
    "    )\n",
    "    draw_connections(decoder_layer, 2, output_layer, 4)\n",
    "\n",
    "    # Annotate VAE-specific elements\n",
    "    ax.text(\n",
    "        -1,\n",
    "        -1.5,\n",
    "        r\"$\\mu$\",\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "        color=\"black\",\n",
    "        ha=\"center\",\n",
    "    )\n",
    "    ax.text(\n",
    "        -1,\n",
    "        1.5,\n",
    "        r\"$\\sigma^2$\",\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "        color=\"black\",\n",
    "        ha=\"center\",\n",
    "    )\n",
    "    ax.text(\n",
    "        -0.3,\n",
    "        0.3,\n",
    "        r\"$\\mathbf{z} \\sim \\mathcal{N}(\\mu, \\sigma^2)$\",\n",
    "        fontsize=12,\n",
    "        fontstyle=\"italic\",\n",
    "        color=\"black\",\n",
    "        ha=\"center\",\n",
    "    )\n",
    "    ax.text(\n",
    "        2,\n",
    "        -1.8,\n",
    "        \"Sampled Latent Vector\",\n",
    "        fontsize=10,\n",
    "        ha=\"center\",\n",
    "        fontstyle=\"italic\",\n",
    "    )\n",
    "    ax.text(4, -3, \"Reconstructed Output\", ha=\"center\", fontsize=10)\n",
    "\n",
    "    # Draw rectangles for latent space distribution\n",
    "    ax.add_patch(\n",
    "        Rectangle(\n",
    "            (-1.8, -2),\n",
    "            1.6,\n",
    "            4,\n",
    "            edgecolor=\"black\",\n",
    "            facecolor=\"none\",\n",
    "            linestyle=\"--\",\n",
    "            linewidth=1.5,\n",
    "        )\n",
    "    )\n",
    "    ax.text(-1.8, 2.3, \"Latent Distribution\", fontsize=10, ha=\"left\")\n",
    "\n",
    "    # Add title and clean up\n",
    "    ax.set_xlim(-5, 5)\n",
    "    ax.set_ylim(-4, 4)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    # Save the figure as a high-quality PDF\n",
    "    fig.savefig(output_pdf, format=\"pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "    print(f\"Diagram saved as {output_pdf}\")\n",
    "\n",
    "    # Close the plot\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# Call the function\n",
    "generate_vae_diagram(\"../example/15_vae_architecture.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Setup Graphs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS & Word per caption distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download necessary resources\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "\n",
    "pos_map = {\n",
    "    \"NN\": \"Nouns\",\n",
    "    \"NNS\": \"Nouns\",\n",
    "    \"NNP\": \"Nouns\",\n",
    "    \"NNPS\": \"Nouns\",\n",
    "    \"VB\": \"Verbs\",\n",
    "    \"VBD\": \"Verbs\",\n",
    "    \"VBG\": \"Verbs\",\n",
    "    \"VBN\": \"Verbs\",\n",
    "    \"VBP\": \"Verbs\",\n",
    "    \"VBZ\": \"Verbs\",\n",
    "    \"JJ\": \"Adjectives\",\n",
    "    \"JJR\": \"Adjectives\",\n",
    "    \"JJS\": \"Adjectives\",\n",
    "    \"RB\": \"Adverbs\",\n",
    "    \"RBR\": \"Adverbs\",\n",
    "    \"RBS\": \"Adverbs\",\n",
    "    \"PRP\": \"Pronouns\",\n",
    "    \"PRP$\": \"Pronouns\",\n",
    "    \"WP\": \"Pronouns\",\n",
    "    \"WP$\": \"Pronouns\",\n",
    "}\n",
    "\n",
    "\n",
    "def process_text(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    pos_counts = {\n",
    "        \"Nouns\": set(),\n",
    "        \"Verbs\": set(),\n",
    "        \"Adjectives\": set(),\n",
    "        \"Adverbs\": set(),\n",
    "        \"Pronouns\": set(),\n",
    "    }\n",
    "    word_counts = []\n",
    "\n",
    "    for text in df[\"raw_text\"].dropna():\n",
    "        words = word_tokenize(text.lower())\n",
    "        word_counts.append(len(words))\n",
    "        pos_tags = pos_tag(words)\n",
    "        for word, tag in pos_tags:\n",
    "            category = pos_map.get(tag)\n",
    "            if category:\n",
    "                pos_counts[category].add(word)\n",
    "\n",
    "    pos_vocab_sizes = {k: len(v) for k, v in pos_counts.items()}\n",
    "    return pos_vocab_sizes, word_counts\n",
    "\n",
    "\n",
    "def plot_vocab_size(pos_vocab_sizes, save_path):\n",
    "    plt.figure(figsize=(8, 5), dpi=150)\n",
    "    bars = plt.bar(\n",
    "        pos_vocab_sizes.keys(),\n",
    "        pos_vocab_sizes.values(),\n",
    "        color=[\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\"],\n",
    "    )\n",
    "    split_name = save_path.split(\"_\")[1]\n",
    "    plt.xlabel(\"POS Category\")\n",
    "    plt.ylabel(\"Vocabulary Size\")\n",
    "    plt.title(f\"{split_name} Split Vocabulary Size per POS Category\")\n",
    "    plt.grid(axis=\"y\", linestyle=\"-\", alpha=0.3)\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            yval,\n",
    "            int(yval),\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=10,\n",
    "        )\n",
    "    plt.savefig(save_path, format=\"pdf\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_word_distribution(word_counts, save_path):\n",
    "    plt.figure(figsize=(8, 5), dpi=150)\n",
    "    counts, bins, patches = plt.hist(\n",
    "        word_counts,\n",
    "        bins=range(8, max(word_counts) + 2),\n",
    "        weights=[100.0 / len(word_counts)] * len(word_counts),\n",
    "        edgecolor=\"black\",\n",
    "        alpha=0.7,\n",
    "        color=\"#1f77b4\",\n",
    "    )\n",
    "    plt.xlabel(\"Number of Words per Caption\")\n",
    "    plt.ylabel(\"Percentage of Captions\")\n",
    "    plt.title(\"Distribution of Number of Words per Caption\")\n",
    "    plt.grid(axis=\"y\", linestyle=\"-\", alpha=0.3)\n",
    "    plt.savefig(save_path, format=\"pdf\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def caption_plots(input_file, vocab_save_path, word_dist_save_path):\n",
    "    pos_vocab_sizes, word_counts = process_text(input_file)\n",
    "    plot_vocab_size(pos_vocab_sizes, vocab_save_path)\n",
    "    plot_word_distribution(word_counts, word_dist_save_path)\n",
    "\n",
    "\n",
    "caption_plots(\n",
    "    \"../curated_clotho_captions/development_captions.csv\",\n",
    "    \"../example/21_Development_vocab_size.pdf\",\n",
    "    \"../example/22_Development_word_distribution.pdf\",\n",
    ")\n",
    "caption_plots(\n",
    "    \"../curated_clotho_captions/validation_captions.csv\",\n",
    "    \"../example/23_Validation_vocab_size.pdf\",\n",
    "    \"../example/24_Validation_word_distribution.pdf\",\n",
    ")\n",
    "caption_plots(\n",
    "    \"../curated_clotho_captions/evaluation_captions.csv\",\n",
    "    \"../example/25_Evaluation_vocab_size.pdf\",\n",
    "    \"../example/26_Evaluation_word_distribution.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Length Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_audio_durations(audio_folder):\n",
    "    durations = []\n",
    "    audio_files = [\n",
    "        f\n",
    "        for f in os.listdir(audio_folder)\n",
    "        if f.endswith(\".wav\") or f.endswith(\".mp3\")\n",
    "    ]\n",
    "    for filename in tqdm(audio_files, desc=\"Processing audio files\"):\n",
    "        file_path = os.path.join(audio_folder, filename)\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "        durations.append(librosa.get_duration(y=y, sr=sr))\n",
    "    return durations\n",
    "\n",
    "\n",
    "def plot_audio_durations(durations, save_path):\n",
    "    split_name = save_path.split(\"_\")[1]\n",
    "    plt.figure(figsize=(8, 5), dpi=150)\n",
    "    bins = np.arange(\n",
    "        15, 35, 2.5\n",
    "    )  # Bins from 15 to 35 with a size of 2.5 seconds\n",
    "    counts, _, patches = plt.hist(\n",
    "        durations, bins=bins, edgecolor=\"black\", alpha=0.7, color=\"orange\"\n",
    "    )\n",
    "    plt.xlabel(\"Audio Duration (seconds)\")\n",
    "    plt.ylabel(\"Audio Count\")\n",
    "    plt.title(f\"{split_name} Split Audio Duration Distribution\")\n",
    "    plt.grid(axis=\"y\", linestyle=\"-\", alpha=0.3)\n",
    "\n",
    "    # Add count labels on top of the bars\n",
    "    for count, patch in zip(counts, patches):\n",
    "        height = patch.get_height()\n",
    "        plt.text(\n",
    "            patch.get_x() + patch.get_width() / 2,\n",
    "            height,\n",
    "            f\"{int(count)}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=10,\n",
    "        )\n",
    "\n",
    "    plt.savefig(save_path, format=\"pdf\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "durations = get_audio_durations(\"../data/Clotho/development\")\n",
    "plot_audio_durations(durations, \"../example/27_Development_durations.pdf\")\n",
    "durations = get_audio_durations(\"../data/Clotho/validation\")\n",
    "plot_audio_durations(durations, \"../example/28_Validation_durations.pdf\")\n",
    "durations = get_audio_durations(\"../data/Clotho/evaluation\")\n",
    "plot_audio_durations(durations, \"../example/29_Evaluation_durations.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all caption plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to convert transparent images to white background\n",
    "def add_white_bg(image):\n",
    "    if image.shape[2] == 4:  # If the image has an alpha channel (RGBA)\n",
    "        bgr = image[:, :, :3]\n",
    "        alpha = image[:, :, 3]\n",
    "        bgr[alpha == 0] = [255, 255, 255]  # Replace transparent with white\n",
    "        return bgr\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "# Function to create a figure with 2 subplots (side by side) and save as PDF\n",
    "def create_figure(images, titles, output_path):\n",
    "    fig = plt.figure(figsize=(12, 6))  # Adjust the size for side-by-side images\n",
    "\n",
    "    # Create subplots (2 columns, 1 row)\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax2 = fig.add_subplot(122)\n",
    "\n",
    "    # Plot images and titles\n",
    "    for i, ax in enumerate([ax1, ax2]):\n",
    "        ax.imshow(images[i])\n",
    "        ax.set_title(titles[i], fontsize=14, fontweight=\"bold\")\n",
    "        ax.axis(\"off\")  # Hide axes\n",
    "\n",
    "    # Remove space between subplots\n",
    "    plt.subplots_adjust(left=0, right=1, top=1, bottom=0, wspace=0, hspace=0)\n",
    "\n",
    "    # Save the figure as PDF\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches=\"tight\", facecolor=\"white\", pad_inches=0, format='pdf')\n",
    "    print(f\"Figure saved as {output_path}\")\n",
    "\n",
    "# Load images with alpha channel (transparency)\n",
    "img_a = cv2.imread(\"../example/30_raw_data.png\", cv2.IMREAD_UNCHANGED)\n",
    "img_b = cv2.imread(\"../example/31_processed_data.png\", cv2.IMREAD_UNCHANGED)\n",
    "img_c = cv2.imread(\"../example/32_agen_mid_data.png\", cv2.IMREAD_UNCHANGED)\n",
    "img_d = cv2.imread(\"../example/33_agen_data.png\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Convert transparent portions to white background\n",
    "img_a = add_white_bg(img_a)\n",
    "img_b = add_white_bg(img_b)\n",
    "img_c = add_white_bg(img_c)\n",
    "img_d = add_white_bg(img_d)\n",
    "\n",
    "# Convert images to RGB (Matplotlib uses RGB, OpenCV uses BGR)\n",
    "img_a = cv2.cvtColor(img_a, cv2.COLOR_BGR2RGB)\n",
    "img_b = cv2.cvtColor(img_b, cv2.COLOR_BGR2RGB)\n",
    "img_c = cv2.cvtColor(img_c, cv2.COLOR_BGR2RGB)\n",
    "img_d = cv2.cvtColor(img_d, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Titles for subfigures\n",
    "titles1 = [\"Fig. a\", \"Fig. b\"]\n",
    "titles2 = [\"Fig. c\", \"Fig. d\"]\n",
    "\n",
    "# Create and save the first figure (a and b)\n",
    "create_figure([img_a, img_b], titles1, \"../example/34_figure_ab.pdf\")\n",
    "\n",
    "# Create and save the second figure (c and d)\n",
    "create_figure([img_c, img_d], titles2, \"../example/34_figure_cd.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def add_white_bg(image):\n",
    "    \"\"\"\n",
    "    Convert transparent images to have a white background.\n",
    "\n",
    "    @param np.ndarray image: Input image with potential alpha channel.\n",
    "    :return np.ndarray: Image with transparency replaced by white.\n",
    "    \"\"\"\n",
    "    if image.shape[2] == 4:  # If the image has an alpha channel (RGBA)\n",
    "        bgr = image[:, :, :3]\n",
    "        alpha = image[:, :, 3]\n",
    "        bgr[alpha == 0] = [255, 255, 255]  # Replace transparent with white\n",
    "        return bgr\n",
    "    return image\n",
    "\n",
    "def create_figure(images, titles, output_path):\n",
    "    \"\"\"\n",
    "    Create a figure with a 2-column layout and save as a PDF.\n",
    "\n",
    "    @param list images: List of images to be displayed.\n",
    "    @param list titles: Corresponding titles for each image.\n",
    "    @param str output_path: File path to save the output PDF.\n",
    "    \"\"\"\n",
    "    num_images = len(images)\n",
    "    num_rows = math.ceil(num_images / 2)  # Compute required rows\n",
    "    fig, axes = plt.subplots(num_rows, 2, figsize=(12, 6 * num_rows))\n",
    "    axes = np.array(axes).reshape(-1)  # Flatten in case of single row\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "        if i < num_images:\n",
    "            ax.imshow(images[i])\n",
    "            ax.set_title(titles[i], fontsize=14, fontweight=\"bold\")\n",
    "        ax.axis(\"off\")  # Hide axes\n",
    "\n",
    "    plt.subplots_adjust(left=0, right=1, top=1, bottom=0, wspace=0, hspace=0)\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches=\"tight\", facecolor=\"white\", pad_inches=0, format='pdf')\n",
    "    print(f\"Figure saved as {output_path}\")\n",
    "\n",
    "# Load image paths\n",
    "image_paths = [\n",
    "    \"../example/30_raw_data.png\",\n",
    "    \"../example/31_processed_data.png\",\n",
    "    \"../example/32_agen_mid_data.png\",\n",
    "    \"../example/33_agen_data.png\",\n",
    "    \"../example/34_extra_data.png\"  # Example extra image\n",
    "]\n",
    "\n",
    "# Load and preprocess images\n",
    "images = []\n",
    "titles = []\n",
    "for i, path in enumerate(image_paths):\n",
    "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    img = add_white_bg(img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    images.append(img)\n",
    "    titles.append(f\"Fig. {chr(97 + i)}\")  # Generate titles (a, b, c...)\n",
    "\n",
    "# Save the figure\n",
    "create_figure(images, titles, \"../example/combined_figure.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "def add_white_bg(image):\n",
    "    \"\"\"\n",
    "    Convert transparent images to have a white background.\n",
    "\n",
    "    @param np.ndarray image: Input image with potential alpha channel.\n",
    "    :return np.ndarray: Image with transparency replaced by white.\n",
    "    \"\"\"\n",
    "    if image.shape[2] == 4:  # If the image has an alpha channel (RGBA)\n",
    "        bgr = image[:, :, :3]\n",
    "        alpha = image[:, :, 3]\n",
    "        bgr[alpha == 0] = [255, 255, 255]  # Replace transparent with white\n",
    "        return bgr\n",
    "    return image\n",
    "\n",
    "def create_figure(images, titles, output_path):\n",
    "    \"\"\"\n",
    "    Create a figure with a 2-column layout and save as a PDF.\n",
    "\n",
    "    @param list images: List of images to be displayed.\n",
    "    @param list titles: Corresponding titles for each image.\n",
    "    @param str output_path: File path to save the output PDF.\n",
    "    \"\"\"\n",
    "    num_images = len(images)\n",
    "    num_rows = math.ceil(num_images / 2)  # Compute required rows\n",
    "    fig, axes = plt.subplots(num_rows, 2, figsize=(12, 6 * num_rows))\n",
    "    axes = np.array(axes).reshape(-1)  # Flatten in case of single row\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "        if i < num_images:\n",
    "            ax.imshow(images[i])\n",
    "            ax.set_title(titles[i], fontsize=14, fontweight=\"bold\")\n",
    "        ax.axis(\"off\")  # Hide axes\n",
    "\n",
    "    plt.subplots_adjust(left=0, right=1, top=1, bottom=0, wspace=0, hspace=0)\n",
    "    plt.savefig(output_path, dpi=600, bbox_inches=\"tight\", facecolor=\"white\", pad_inches=0, format='pdf')\n",
    "    print(f\"Figure saved as {output_path}\")\n",
    "\n",
    "def get_image_paths(folder_path):\n",
    "    \"\"\"\n",
    "    Get all image file paths from the given folder.\n",
    "\n",
    "    @param str folder_path: Path to the folder containing images.\n",
    "    :return list: List of image file paths.\n",
    "    \"\"\"\n",
    "    valid_extensions = {\".png\", \".jpg\", \".jpeg\"}\n",
    "    return [os.path.join(folder_path, f) for f in sorted(os.listdir(folder_path))\n",
    "            if os.path.splitext(f)[1].lower() in valid_extensions]\n",
    "\n",
    "# Define folder path\n",
    "folder_path = \"../temp/cmp_embedd_figs\"\n",
    "\n",
    "# Get image file paths\n",
    "image_paths = get_image_paths(folder_path)\n",
    "\n",
    "# Load and preprocess images\n",
    "images = []\n",
    "titles = []\n",
    "for i, path in enumerate(image_paths):\n",
    "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    img = add_white_bg(img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    images.append(img)\n",
    "    titles.append(f\"Fig. {chr(97 + i)}\")  # Generate titles (a, b, c...)\n",
    "\n",
    "# Save the figure\n",
    "create_figure(images, titles, \"../temp/ez_embedd_figure.pdf\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
