trial_series: absolute/path/to/trial_series_folder

trial_base: absolute/path/to/trial_base_folder


# Configure ray-tune clusters
ray_conf:
    init_args:
        # num_cpus: 1
        # num_gpus: 1
        local_mode: false
        ignore_reinit_error: true
        include_dashboard: false
        _temp_dir: /tmp/ray_temp
    runtime_env:
        env_vars:
            RAY_DEBUG: 1


    trial_stopper: TrialPlateauStopper
    stopper_args:
        metric: stop_metric
        std: 0.001
        num_results: 10
        grace_period: 60
        mode: min


# Configure training, validation, and evaluation data
data_conf:
    train_data: # training data
        dataset: absolute/path/to/Clotho
        audio_data: development_audio_logmels.hdf5
        text_data: development_text.csv
        text_embeds: sbert_embeds.pkl
        text_level: sentence

    val_data: # validation data
        dataset: absolute/path/to/Clotho
        audio_data: validation_audio_logmels.hdf5
        text_data: validation_text.csv
        text_embeds: sbert_embeds.pkl
        text_level: sentence

    eval_data: # evaluation data
        dataset: absolute/path/to/Clotho
        audio_data: evaluation_audio_logmels.hdf5
        text_data: evaluation_text.csv
        text_embeds: sbert_embeds.pkl
        text_level: sentence


# Configure hyper-parameters
param_conf:
    num_epoch: 100
    batch_size: 64
    model: DualEncoderModel
    criterion: infonce_loss
    optimizer: AdamOptimizer
    lr_scheduler: ReduceLROnPlateau


# Model definitions
DualEncoderModel:
    name: DualEncoderModel
    out_norm: L2

    audio_enc:
        name: CNN14Encoder
        init: prior
        weight: absolute/path/to/pretrained_models/CNN14_300.pth
        trainable: true
        out_dim: 300

    text_enc:
        name: SentBERTBaseEncoder
        init: prior
        out_dim: 300


# Criteria
criteria:
    infonce_loss:
        name: LogSoftmaxLoss
        args:
            temperature: 0.07
            dist: dot_product  # dot_product, cosine_similarity


# Optimizer definitions
AdamOptimizer:
    name: Adam
    args:
        lr: 0.001
        weight_decay: 0.0


# Learning rate scheduler definitions
ReduceLROnPlateau:
    name: ReduceLROnPlateau
    args:
        mode: min
        factor: 0.1
        patience: 5
        threshold: 0.005
        threshold_mode: abs
        min_lr: 0.000001
        verbose: true
