{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Expand original caption csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def expand_and_fill(csv_file):\n",
    "  \"\"\"\n",
    "  Expands the CSV by duplicating file names with caption suffixes\n",
    "  and fills caption columns accordingly.\n",
    "\n",
    "  Args:\n",
    "      csv_file (str): Path to the CSV file.\n",
    "\n",
    "  Returns:\n",
    "      pd.DataFrame: DataFrame with expanded entries and filled captions.\n",
    "  \"\"\"\n",
    "\n",
    "  df = pd.read_csv(csv_file)\n",
    "  expanded_data = []\n",
    "\n",
    "  for _, row in df.iterrows():\n",
    "    expanded_data.append(row.to_dict()) # Add original row\n",
    "\n",
    "    file_name = row['file_name']\n",
    "    for i in range(1, 6):\n",
    "      new_row = row.to_dict() # Copy the entire row\n",
    "      new_row['file_name'] = f\"{file_name[:-4]}_cap_{i}.wav\"\n",
    "\n",
    "      # Set all caption columns to \"N/A\" except the matching one\n",
    "      for j in range(1, 6):\n",
    "        new_row[f'caption_{j}'] = 'N/A' if i != j else row[f'caption_{j}']\n",
    "\n",
    "      expanded_data.append(new_row)\n",
    "\n",
    "  return pd.DataFrame(expanded_data)\n",
    "\n",
    "# Example usage\n",
    "for split in ['development', 'validation', 'evaluation']:\n",
    "  expanded_df = expand_and_fill(f'./curated_clotho_captions/clotho_captions_{split}.csv')\n",
    "  expanded_df.to_csv(f'./agen_clotho_captions/clotho_expanded_captions_{split}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convert above generated csv's to row wise audio-raw_text-text pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "def parse_text(text):\n",
    "    \"\"\"Remove punctuation, convert to lowercase, and remove extra spaces.\"\"\"\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove extra spaces\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "def transform_csv(input_csv_fp, output_csv_fp):\n",
    "    '''From a normal file having a wav_fname with 5 caption columns, create 5 rows, 1 for each non-na caption column'''\n",
    "    # Load the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(input_csv_fp)\n",
    "\n",
    "    # Create a new DataFrame for the transformed data\n",
    "    transformed_df = pd.DataFrame(columns=['fname', 'raw_text', 'text'])\n",
    "\n",
    "    # Iterate through each row in the original DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        file_name = row['file_name']\n",
    "        for i in range(1, 6):  # Loop through caption_1 to caption_num\n",
    "            caption = row[f'caption_{i}']\n",
    "            if pd.notna(caption):  # Ensure the caption is not NaN\n",
    "                # Add the row to the transformed DataFrame\n",
    "                transformed_df = pd.concat([transformed_df, pd.DataFrame([{\n",
    "                    'fname': file_name,\n",
    "                    'raw_text': caption,\n",
    "                    'text': parse_text(caption)\n",
    "                }])], ignore_index=True)\n",
    "\n",
    "    # Save the transformed DataFrame to the new CSV file\n",
    "    transformed_df.to_csv(output_csv_fp, index=False)\n",
    "\n",
    "# Provide the path to your input CSV file and the desired output CSV file\n",
    "for split in ['development', 'validation', 'evaluation']:\n",
    "    input_csv_fp = f'./agen_clotho_captions/clotho_expanded_captions_{split}.csv'\n",
    "    output_csv_fp = f'./agen_clotho_captions/agen_captions_{split}.csv'\n",
    "    transform_csv(input_csv_fp, output_csv_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. From the above cell generated csv's, extract the information for every caption columns and create individual csv's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def create_caption_csv_files(input_csv_fp, split, output_dir='./conf_yamls'):\n",
    "    \"\"\"\n",
    "    Creates 5 CSV files, each containing captions for a specific caption index,\n",
    "    combined with the base captions.\n",
    "\n",
    "    Args:\n",
    "        input_csv_fp (str): Path to the input CSV file.\n",
    "        split (str): Identifier for the data split (e.g., 'evaluation', 'train').\n",
    "        output_dir (str, optional): Directory to save the output CSV files.\n",
    "            Defaults to './data'.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(input_csv_fp)\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        caption_index = i\n",
    "        output_subdir = os.path.join(output_dir, f'Clotho_caption_{caption_index}')\n",
    "        os.makedirs(output_subdir, exist_ok=True)\n",
    "\n",
    "        # Filter rows for the current caption index\n",
    "        cap_row = df[df['fname'].str.endswith(f'_cap_{caption_index}.wav')]\n",
    "\n",
    "        # Combine base rows and filtered rows\n",
    "        combined_df = pd.concat([df[~df['fname'].str.contains('_cap_')], cap_row], ignore_index=True)\n",
    "\n",
    "        # Save the combined DataFrame to a CSV file\n",
    "        output_csv_fp = os.path.join(output_subdir, f'{split}_captions.csv')\n",
    "        combined_df.to_csv(output_csv_fp, index=False)\n",
    "\n",
    "for split in ['development']:\n",
    "    input_csv_file = f'./agen_clotho_captions/agen_captions_{split}.csv'\n",
    "    create_caption_csv_files(input_csv_file, split, output_dir='./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. From the expanded csv, generate a single csv file filled with all captions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "# Function to normalize the text by converting to lowercase and removing extra punctuation\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Remove punctuation, convert to lowercase, and remove extra spaces.\"\"\"\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove extra spaces\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('agen_clotho_captions/clotho_expanded_captions_development.csv')\n",
    "\n",
    "# Reshape the dataframe by melting, gathering all caption columns into a single column\n",
    "df_melted = df.melt(id_vars=['file_name'], value_vars=['caption_1', 'caption_2', 'caption_3', 'caption_4', 'caption_5'],\n",
    "                    var_name='caption_column', value_name='raw_text')\n",
    "\n",
    "# Remove rows where the 'raw_text' is 'N/A' or empty\n",
    "df_filtered = df_melted.dropna(subset=['raw_text'])\n",
    "df_filtered = df_filtered[df_filtered['raw_text'] != 'N/A']\n",
    "\n",
    "# Add a new column with normalized text\n",
    "df_filtered['text'] = df_filtered['raw_text'].apply(normalize_text)\n",
    "\n",
    "# Sort the DataFrame to ensure that _cap_{num} files appear just after the original file\n",
    "df_filtered['sort_key'] = df_filtered['file_name'].str.replace(r'_cap_\\d+', '', regex=True)  # Create a sort key\n",
    "df_filtered['is_cap'] = df_filtered['file_name'].str.contains(r'_cap_\\d+')  # Identify if it's a _cap file\n",
    "\n",
    "# Sort by the sort_key first, then by whether it's a _cap file or not\n",
    "df_sorted = df_filtered.sort_values(by=['sort_key', 'is_cap', 'file_name']).drop(columns=['caption_column', 'sort_key', 'is_cap'])\n",
    "\n",
    "# Select only the required columns\n",
    "df_final = df_sorted[['file_name', 'raw_text', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the transformed CSV to a new file\n",
    "df_final.to_csv('agen_clotho_captions/transformed_development.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from typing import Dict\n",
    "\n",
    "def count_files_with_extensions(folder_path: str, extensions: List[str]) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Counts the number of files with each specified extension in a given folder.\n",
    "\n",
    "    :param folder_path: Path to the folder where files will be counted.\n",
    "    :param extensions: List of file extensions to look for (e.g., ['.txt', '.jpg']).\n",
    "    :return: Dictionary with extensions as keys and counts as values.\n",
    "    \"\"\"\n",
    "    counts = {ext: 0 for ext in extensions}  # Initialize a dictionary with each extension set to 0\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            for ext in extensions:\n",
    "                if file.endswith(ext):\n",
    "                    counts[ext] += 1\n",
    "\n",
    "    return counts\n",
    "# Example usage:\n",
    "folder_path = 'data/Clotho_caption_2/development'\n",
    "extensions = ['.wav', '.csv']\n",
    "file_counts = count_files_with_extensions(folder_path, extensions)\n",
    "print(f\"File counts: {file_counts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files into pandas DataFrames\n",
    "def count_fnames(captions_fp, clotho_captions_fp):\n",
    "    '''\n",
    "    Check whether the file_name in clotho_captions_{split}.csv are present 5 times in the {split}_captions.csv or not\n",
    "    '''\n",
    "    captions_file = pd.read_csv(captions_fp)  # First file\n",
    "    clotho_captions_file = pd.read_csv(clotho_captions_fp)  # Second file\n",
    "\n",
    "    # Count occurrences of each fname in the first file\n",
    "    fname_counts = captions_file['fname'].value_counts()\n",
    "\n",
    "    # Extract the file_name column from the second file\n",
    "    file_names = clotho_captions_file['file_name']\n",
    "\n",
    "    # Check if each file_name from the second file occurs exactly 5 times in the first file\n",
    "    for file_name in file_names:\n",
    "        count = fname_counts.get(file_name,0)\n",
    "        if count != 5:\n",
    "            print(f\"{file_name} does NOT occur exactly 5 times in the first file. It occurs {count} times.\")\n",
    "\n",
    "count_fnames(captions_fp='./data/Clotho/development_captions.csv', clotho_captions_fp='./data/clotho_captions_development.csv')\n",
    "count_fnames(captions_fp='./data/Clotho/validation_captions.csv', clotho_captions_fp='./data/clotho_captions_validation.csv')\n",
    "count_fnames(captions_fp='./data/Clotho/evaluation_captions.csv', clotho_captions_fp='./data/clotho_captions_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_captions(file_name, df1, df2):\n",
    "    # Filter df1 rows for the given file_name\n",
    "    df1_filtered = df1[df1['fname'] == file_name]\n",
    "\n",
    "    # Get all captions for the file_name from df2\n",
    "    captions_in_df2 = df2[df2['file_name'] == file_name].iloc[0, 1:].tolist()\n",
    "    # Check if each caption in df2 exists in the 'raw_text' column of the filtered df1\n",
    "    captions_in_df1 = df1_filtered['raw_text'].tolist()\n",
    "    missing_captions = [caption for caption in captions_in_df2 if caption not in captions_in_df1]\n",
    "\n",
    "    if not missing_captions:\n",
    "        print(end = '')\n",
    "    else:\n",
    "        print(f\"Missing captions for '{file_name}': {missing_captions}\")\n",
    "\n",
    "def main_check_function(captions_fp, clotho_captions_fp):\n",
    "    '''\n",
    "    Check whether all the 5 captions from clotho_captions_{split}.csv file are present iteratively in rows in {split}_captions.csv\n",
    "    '''\n",
    "    df1 = pd.read_csv(captions_fp)\n",
    "    df2 = pd.read_csv(clotho_captions_fp)\n",
    "\n",
    "    # Check for each file_name in df2\n",
    "    file_names = df2['file_name']\n",
    "    for file_name in file_names:\n",
    "        check_captions(file_name, df1, df2)\n",
    "\n",
    "\n",
    "main_check_function(captions_fp='./data/Clotho/development_captions.csv', clotho_captions_fp='./curated_clotho_captions/clotho_captions_development.csv')\n",
    "main_check_function(captions_fp='./data/Clotho/validation_captions.csv', clotho_captions_fp='./curated_clotho_captions/clotho_captions_validation.csv')\n",
    "main_check_function(captions_fp='./data/Clotho/evaluation_captions.csv', clotho_captions_fp='./curated_clotho_captions/clotho_captions_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compare_dataframes(df1, df2):\n",
    "    # Ensure both DataFrames have the same shape\n",
    "    if df1.shape != df2.shape:\n",
    "        raise ValueError(\"DataFrames must have the same shape to compare.\")\n",
    "\n",
    "    # Initialize an empty DataFrame to store the differences\n",
    "    diff_df = pd.DataFrame(columns=['col_1', 'col_2'])\n",
    "\n",
    "    # Iterate through each row in the DataFrames\n",
    "    for idx in range(df1.shape[0]):\n",
    "        row1 = df1.iloc[idx]\n",
    "        row2 = df2.iloc[idx]\n",
    "\n",
    "        # Check if there are any differences between the rows\n",
    "        if not row1.equals(row2):\n",
    "            # Append rows from both DataFrames to the diff_df\n",
    "            diff_df = pd.concat([\n",
    "                diff_df,\n",
    "                pd.DataFrame({\n",
    "                    'col_1': [row1.to_dict()],\n",
    "                    'col_2': [row2.to_dict()]\n",
    "                })\n",
    "            ], ignore_index=True)\n",
    "\n",
    "    return diff_df\n",
    "\n",
    "df1 = pd.read_csv('data/Clotho_caption_1/transformed_captions.csv')\n",
    "df2 = pd.read_csv('data/Clotho/development_captions.csv')\n",
    "\n",
    "# Compare the DataFrames\n",
    "diff_df = compare_dataframes(df1, df2)\n",
    "\n",
    "# Save the differences to a CSV file if needed\n",
    "diff_df.to_csv('./data/differences.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
